---
layout: post
title: python으로 데이터 가져오기
date: 2024-04-26 17:29 +0900
description: python으로 데이터 가져오는 방법에 대해서 알아보기
image: ../assets/img/python01.jpg
category: 파이썬
tags: 파이썬 python
published: true
sitemap: true
---

오늘은 python을 이용해 데이터 가져오는 방법에 대해서 알아보려고 하는데요,<br>
그 예시로 음악 사이트의 차트를 가져와보도록 할게요!
<br>

# python

#### 1. 파이썬 설치

▶ python을 시작하기 전 필수로 설치해주어야하는 파일이 있는데<br>
우선 윈도우나 맥 버전의 python 프로그램을 설치해주신 후 VScode Extensions에서 pylance / python / python debugger 3가지를 검색 후 다운받아주세요.<br>

#### 2. requests 설치

▶ 1번에서 필요한 설치가 끝나셨다면 이제 자바스크립트의 터미널창을 켠 후 5개의 pip3 install 파일을 설치해주시면 되는데요,<br>
아래의 requests를 달아두도록 할테니 복붙해서 쓰시면 됩니다!

````bash
    1. pip3 install requests
    : 웹 페이지나 API로부터 데이터를 손쉽게 가져오는 Python 라이브러리
    
    2. pip3 install beautifulsoup4
    : HTML 및 XML 문서를 구문 분석하여 데이터를 추출하기 위한 파이썬 라이브러리

    3. pip3 install lxml
    : XML 및 HTML을 처리하기 위한 파이썬 라이브러리로, 파싱 및 문서 조작에 사용됨

    4. pip3 install pandas
    : 데이터 조작 및 분석을 위한 Python 라이브러리로, 데이터프레임을 다룰 때 유용함

    5. pip3 install selenium
    : 웹 애플리케이션 테스트 자동화를 위한 도구로, 브라우저를 제어하여 웹 페이지를 자동으로 조작할 수 있게 해줌
````

<br>

#### 3. 벅스 차트 가져오기 01

▶ 이제 모든 설치가 끝났으니 본격적으로 차트를 가져와보도록 할텐데 저는 벅스 차트를 가져와보려고 합니다. 먼저 해당 데이터를 저장하기 위한 파이썬 폴더와 'bugsmusic.py' 파일을 만들어줍니다.<br>

````bash
import requests as req
from bs4 import BeautifulSoup as bs
import pandas as pd

res = req.get("https://music.bugs.co.kr/chart")

soup = bs(res.text, "lxml")
````

▶ 먼저, 웹 스크래핑을 위해 사용되는 라이브러리인 requests, 웹 페이지에서 데이터를 추출하기 위한 BeautifulSoup, 그리고 데이터를 분석하고 조작하기 위한 pandas를 사용해줄건데요, 사용하는 이유는 아래와 같습니다.
<br>

1. import requests as req & res = req.get("https://music.bugs.co.kr/chart")<br>
: 웹 페이지에 GET 요청을 보내고, 해당 페이지의 HTML 데이터를 가져오는 데 사용하기 위함이며,<br>
req.get("https://music.bugs.co.kr/chart")는 'https://music.bugs.co.kr/chart' 주소로 GET 요청을 보내서 응답을 받아오는 것을 의미하고 이를 res라는 변수에 저장합니다.

<br>

2. from bs4 import BeautifulSoup as bs & soup = bs(res.text, "lxml")<br>
: HTML 데이터를 파싱하여 필요한 정보를 추출하기 위해 사용되며,<br>
bs(res.text, "lxml")는 res.text에서 HTML을 파싱하고, lxml 파서를 사용하여 BeautifulSoup 객체인 soup를 생성하는 것을 의미합니다.

<br>

3. import pandas as pd<br>
: 데이터를 효율적으로 분석하고 관리하기 위해 사용되며,<br>
 이 코드에서는 웹 페이지에서 가져온 데이터를 DataFrame으로 변환하여 처리할 수 있습니다.

<br>

#### 4. 벅스 차트 가져오기 02

▶ 차트 순위를 가져오기 위해선 해당 차트 홈페이지 내 검사를 통해 스크립트 구성을 같이 확인해야 하는데요,<br>
저는 랭킹 순위, 곡제목, 가수 이렇게 3가지를 가져올 예정이며 각각의 정보는 ranking, title, artist로 이름을 지정해주었습니다.<br>
그런 다음 검사를 통해 확인해보면 각각의 정보가 어떤 클래스에 속해있는지를 확인할 수 있는데 벅스의 경우는 아래와 같습니다.<br>
직접 검사를 통해 확인해보신다면 좀 더 이해가 빠르실거예요! 

````bash
ranking = soup.select(".ranking > strong") // .ranking이라는 클래스 안 strong 태그에 랭킹 정보
title = soup.select(".title > a") // .title이라는 클래스 안 a 태그에 곡제목 정보
artist = soup.select(".artist > a:nth-child(1)")  // .artist이라는 클래스 안 a 태그에 가수 정보
````

💡 artist 정보에 **a:nth-child(1)** 처럼 nth:child()를 해준 이유는 피처링이 있을 경우 가수가 1명 이상이 되기 떄문입니다.

<br>

#### 5. 벅스 차트 가져오기 03

▶ 그 다음 위에서 추출한 데이터 정보들을 저장해주도록 하겠습니다.<br>
이렇게 저장된 데이터는 순위(rankingList), 곡 제목(titleList), 아티스트(artistList)의 리스트 형태로 나타나며, 이후에 이 데이터를 활용하여 필요한 작업을 수행할 수 있습니다. 

````bash
# 데이터 저장
rankingList = [r.text.strip() for r in ranking]
titleList = [t.text.strip() for t in title]
artistList = [a.text.strip() for a in artist]
````

1. rankingList = [r.text.strip() for r in ranking]<br>
: ranking 리스트에 있는 각 요소(strong 태그)에서 텍스트를 추출하고 양쪽의 공백을 제거한 후 rankingList에 저장합니다. 이렇게 하면 각 노래의 순위가 저장됩니다.

<br>

2. titleList = [t.text.strip() for t in title]<br>
: title 리스트에 있는 각 요소(a 태그)에서 텍스트를 추출하고 양쪽의 공백을 제거한 후 titleList에 저장합니다. 이렇게 하면 각 노래의 제목이 저장됩니다.

<br>

3. artistList = [a.text.strip() for a in artist]<br>
: artist 리스트에 있는 각 요소(a 태그)에서 텍스트를 추출하고 양쪽의 공백을 제거한 후 artistList에 저장합니다. 이렇게 하면 각 노래의 아티스트가 저장됩니다.

<br>

#### 6. 벅스 차트 가져오기 04

▶ 마지막으로 저장된 데이터에 프레임을 생성해준 후 JSON파일로 저장하면 끝입니다.

````bash
# 데이터 프레임 생성
chart_df = pd.DataFrame({
    'Ranking': rankingList,
    'Title': titleList,
    'Artist': artistList
})

# JSON 파일로 저장
chart_df.to_json("busChart100.json", force_ascii=False, orient="records")
````

1. pd.DataFrame() 함수를 사용하여 데이터프레임을 생성한 후 각 열의 이름과 해당 열에 들어갈 데이터를 지정해줍니다.<br>
저는 'Ranking', 'Title', 'Artist' 열을 만들었고, 각각 rankingList, titleList, artistList라는 데이터를 넣어서 데이터프레임을 만들어주었습니다.

<br>

2. to_json() 메서드를 사용하여 데이터프레임을 JSON 파일로 변환하여 저장하는데,<br>
첫 번째 인자로 파일 이름을 지정하고, force_ascii=False를 이용해 ASCII 문자만 사용하지 않도록 설정해준 후 orient="records"로 각 레코드를 JSON 객체로 변환하여 파일에 저장하도록 해주었습니다.

<br>

3. 그 다음 자바스크립트 내 터미널에 아래처럼 입력해준다면 만들어둔 파이썬 폴더에 JSON파일이 생긴 걸 확인할 수 있습니다.

````bash
python bugsmusic.py -> python (파일명)
````

<br>
오늘은 python을 이용해 데이터 가져오는 방법에 대해 알아봤는데요,<br>
위의 방법을 활용해 다른 음악 사이트의 차트들도 만들어보시면 어떨까요?